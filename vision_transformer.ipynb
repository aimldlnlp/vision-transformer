{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYQqFEd3yRzdaGaI1RiPyS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aimldlnlp/vision-transformer/blob/main/vision_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This project is about implementing vision transformer. The code is from the following video: https://youtu.be/j3VNqtJUoz0?si=MUE8qp42kntSpV6O.\n",
        "# You can check the notebook here: https://colab.research.google.com/drive/1P9TPRWsDdqJC6IvOxjG2_3QlgCt59P0w?usp=sharing"
      ],
      "metadata": {
        "id": "5SJXrqErQxlR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bOPYGu_vPywc"
      },
      "outputs": [],
      "source": [
        "# !pip install einops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image patching"
      ],
      "metadata": {
        "id": "CdZvGDVtP5sW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "import matplotlib.pyplot as plt\n",
        "from random import random\n",
        "from torchvision.transforms import Resize, ToTensor\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from einops import rearrange"
      ],
      "metadata": {
        "id": "3BECBgF9P4Xg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_tensor = [Resize((144, 144)), ToTensor()]\n",
        "\n",
        "class Compose(object):\n",
        "  def __init__(self, transforms):\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __call__(self, img, target):\n",
        "    for t in self.transforms:\n",
        "      img = t(img)\n",
        "    return img, target\n",
        "\n",
        "  def show_images(images, num_samples = 40, cols = 8):\n",
        "    \"\"\" Plots some samples from the dataset \"\"\"\n",
        "    plt.figure(figsize = (15, 15))\n",
        "    idx = int(len(dataset)/num_samples)\n",
        "    print(images)\n",
        "    for i, img in enumerate(images):\n",
        "      if i % idx == 0:\n",
        "        plt.subplot(int(num_samples/cols) + 1, cols, int(i/idx) + 1)\n",
        "        plt.imshow(to_pil_image(img))\n",
        "\n",
        "dataset = OxfordIIITPet(root = '.', download = True, transform = Compose(to_tensor))\n",
        "show_images(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "o_yEDH-rRgS2",
        "outputId": "f36870a7-d7c7-4be7-a680-a578dc0964fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/pets/images.tar.gz to oxford-iiit-pet/images.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792M/792M [00:18<00:00, 42.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting oxford-iiit-pet/images.tar.gz to oxford-iiit-pet\n",
            "Downloading https://thor.robots.ox.ac.uk/pets/annotations.tar.gz to oxford-iiit-pet/annotations.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19.2M/19.2M [00:01<00:00, 18.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting oxford-iiit-pet/annotations.tar.gz to oxford-iiit-pet\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'show_images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a7570093fb1c>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOxfordIIITPet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mshow_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'show_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1rC0lqyS-Hd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}